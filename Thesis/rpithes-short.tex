%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%                       rpithes-short.tex                         %
%         Template for a short thesis all in one file             %
%        (titlepage info below assumes masters degree}            %
%  Just run latex (or pdflatex) on this file to see how it looks  %
%      Be sure to run twice to get correct TOC and citations      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%
%  To produce the abstract title page followed by the abstract,
%  see the template file, "abstitle-mas.tex"
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{thesis}
\usepackage{graphicx}   % if you want to include graphics files
\usepackage{pdflscape}

% Use the first command below if you want captions over 1 line indented.
% A side effect of this is to remove the use of bold for captions. 
% To restore bold, also include the second line below.
%\usepackage[hang]{caption}     % to indent subsequent lines of captions
%\renewcommand{\captionfont}{\bfseries} % only needed with caption package;
                                        %   otherwise bold is default)
                                        
%%%%%%%%%%%%%%%%%%%%  supply titlepage info  %%%%%%%%%%%%%%%%%%%%%
\thesistitle{\bf NSL Spindle\\Map-Reduce at the Edge In a V2V Environment}        
\author{William Rory Kronmiller}        
\degree{Master of Science}
\department{Computer Science} % provide your area of study here; e.g.,
%  "Mechanical Engineering", "Nuclear Engineering", "Physics", etc.
\thadviser{Dr. Stacy Patterson}
%\cothadviser{First co-adviser} %if needed
%\cocothadviser{Second co-adviser} % if needed
%  For a masters project use \projadviser instead of \thadviser, 
%  and \coprojadviser and \cocoprojadviser if needed. 
\submitdate{March 3\\(For Graduation May 2017)}        
%\copyrightyear{1685}  % if date omitted, current year is used. 
%%%%%%%%%%%%%%%%%%%%%   end titlepage info  %%%%%%%%%%%%%%%%%%%%%%
      
\begin{document} 
\titlepage             % Print titlepage   
%\copyrightpage        % optional         
\tableofcontents       % required 
\listoftables          % required if there are tables
\listoffigures         % required if there are figures

\specialhead{ACKNOWLEDGMENT}
The acknowledgment text goes here. Unlike chapter headings, 
this heading is not numbered.
% Personal thing

\specialhead{ABSTRACT}
Write your abstract here. Again, the heading does receive a number.

\chapter{INTRODUCTION}
    Spindle serves as a scalable hybrid vehicle-to-vehicle and vehicle-to-internet architecture
    for efficient near-real-time processing of streaming sensor data from network-connected vehicles.
    According to a 2015 Hitachi white-paper, some contemporary vehicles produce as much
    as 25 gigabytes of data every hour with prototype vehicles fitted with "cameras and additional
    sensors" producing up to 250 gigabytes per hour \cite{hitachi}. At the same time, work is underway
    to develop and test a variety of communications systems for connecting vehicles to one another
    and to road infrastructure and the internet \cite{connectivitypaper}. Spindle addresses the problem
    of managing the vast quantities of available vehicle data by applying the map/reduce \cite{mapreduce}
    paradigm to logical clusters of interconnected vehicles. In particular, Spindle exploits edge-computation
    by exchanging data over vehicle-to-vehicle communications systems in order to reduce the amount of data
    that must be sent over the internet to the cloud. Spindle is designed to support the use case
    of a developer or analyst writing a streaming map/reduce program that can then be deployed to the cloud
    and distributed to clusters of vehicles; vehicles in each cluster can apply the map operation to their
    incoming data streams and send the map outputs to a single leader (Clusterhead); the Clusterhead then
    applies the reduce operation to a buffer of incoming mapper outputs and sends the result of the reduce
    operation to the cloud, which forwards the data to the user's client program where the data can be
    displayed or further analyzed.

    Our contribution is to demonstrate the bandwidth savings of performing map/reduce at the edge, in
    vehicle networks, by implementing a subset of the Spindle architecture inside a simulation framework.
    We implement the data Spindle processing pipeline for vehicles and Clusterheads, which we then integrate
    with a system that provides realistic mobility and connectivity data, such that we can simulate vehicles
    moving through space, forming clusters, processing map/reduce queries, and producing outputs to send to
    the cloud. We instrument the simulator to measure the number of bytes outputby simulated Clusterheads,
    destined for the cloud. We work in collaboration with Mike Wittie of Montana State University to obtain
    realistic position and connectivity information for vehicles in the simulation. We also work in
    collaboration with Xiaotian Duan, from whose work we get vehicle-to-cluster assignments over time
    for our simulation. In evaluating our experiments, we focus in particular on the effect of different
    reducer window sizes on the amount of data sent to the cloud; in so doing, we explore the trade-off
    between resolution and latency versus bandwidth consumption. Having a smaller reducer window means
    that reduced messages are sent more frequently and client programs are given more data points to
    analyze, while having a larger reducer window size means more messages can be batched together for
    reduction before data is transmitted to the cloud. We also explore the effects of regions with
    differing vehicle densities on bandwidth savings; regions of space that have a higher density
    of vehicles offer the opportunity to form larger clusters and to reduce the total number
    of clusters relative to the total number of vehicles present; a smaller number of clusters
    equates to a smaller number of Clusterheads transmitting data at any given time window, which
    has an effect on overall bandwidth usage.

\chapter{Background and Related Work}
    \section{Connected Vehicles}
        %TODO: VANET, quote bandwidth thing again, radio connectivity is different in each direction, etc...
    \subsection{Vehicle Clusters}
        %TODO: C-DRIVE etc...
    \section{Cloud Data Processing Technologies}
        The past few years have seen a number of critical developments in IT
        infrastructure and data processing software that, combined, provide
        a formidable platform for extracting useful information from vast
        quantities of data at scale.
        \paragraph{Amazon Web Services}
            Amazon Web Services (AWS) is a set of "Cloud Computing" offerings
            from Amazon.com that provide access to elastic computation and storage
            resources on an "on-demand" basis \cite{aws}. One particularly valuable
            service offered is EC2, which provides access to collections of virtual
            machines running on Amazon's cloud. These EC2 virtual machines (instances)
            can be used to perform resource-intensive cluster computing operations without
            the need for fixed infrastructure on the part of the end-user. One way in which
            a user can purchase access to EC2 instances is through Spot Requests, wherein the
            user places a bid for the maximum amount s/he is willing to pay per hour for a given
            EC2 instance configuration. If the user is not outbid, then the user is given access
            to an instance of the specified configuration. As soon as the user is outbid (within
            approximately 2 minutes), the user's EC2 instance is shut down and its local data is
            lost. Spot Requests provide very low cost access to computing resources at the cost of
            reliability.%TODO: cite quote how?, TODO: cite docs for spot requests
            Finally of note, Amazon provides an object storage layer - one can associate a key string
            with some binary blob that is stored in a replicated file system - called S3.
    \subsection{Spark Streaming}
        One framework that is capable of processing large quantities of data in a distributed fashion,
        such as on a cluster of EC2 instances, is Apache Spark. Spark offers a micro-batch package for
        processing streaming data called Spark Streaming. Spark Streaming allows a developer (or other
        analyst) to manipulate time-bounded batches of streaming data tuples by writing a program that
        performs immutable transformations such as map, filter, and reduce on a Spark Streaming abstraction
        called a DStream. Spark is able to take the client program, break it up into "stages" in which
        all processing across tuples can occur in parallel, then partition each stream and stage
        across nodes to be processed in parallel. %TODO: clarify how stages work (also double-check)
        In sum, Spark Streaming provides a computing framework and a set of abstractions which allow
        a developer to write map/reduce-style programs for streaming data with relative ease
        \cite{spark:streaming}.
    \subsection{Kafka}
        %TODO
    \section{Other Software}
    \subsection{Akka}
        %TODO
    \subsection{Postgres}
        %TODO
%TODO
%TODO: need to explain how spark works, how akka works, 

%TODO: related works (mention that C-DRIVE came up with clustered architecture)
%TODO (meeting): fix positioing of page numbers
%

%TODO (meeting): feel free to check in by email to get feedback if necessary

\chapter{System Architecture}
    Spindle provides a novel streaming data processing platform by building on
    existing cutting edge and industry standard distributed systems, primarily
    from the Apache ecosystem. 

    The Spindle system consists of three major components: a set of Apache Spark %TODO: cite
    streaming programs managed by one or more clients, a custom data ingestion and
    query management Middleware, and edge computing software running on network
    connected vehicles.
    
    Spindle operates on the vehicle level as a Scala
    \cite{scala} program running on the Akka \cite{akka} framework; this program
    is responsible for handling cluster formation, data collection, and edge
    computation.

    Data passes through components of the Vehicle software in the form of 
    messages sent to Kafka \cite{kafka} topics. Similarly, data is transferred
    at the cloud layer using Kafka.

    Clients receive data from the middleware as Kafka messages that a custom Spark \cite{spark}
    library processes into DStream tuples which can be further processed using any of the available
    Spark streaming operations written for DStreams and RDDs.

\section{Theorized Architecture}
%GENERAL NOTE: need to be able to understand what the figure is solely through the caption (fine to duplicate text)
    %TODO: walk through spark query, middleware update, propagation through vehicle networks, vehicle-level-map, clusterhead-reduce, transmission to middleware, transmission to spark streaming, secondary reduce, etc..
    \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{binImages/theoretical-system.png}
        \caption{A diagram of the theorized system's major components. Vehicles
        send data to their Cluster Heads, which perform reduce operations over
        incoming mapped tuples. The resultant reduced tuples are then sent to
        the middleware to be distributed to the connected Spark jobs.}
        \label{fig:theoretical:component}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics[height=4in, width=6in]{binImages/theoretical-sequence.png}
        \caption{A sequence diagram showing how a query passes from a connected Spark job
        through the middleware and vehicle systems and how the reduced results then return
        to the Spark job.}
        \label{fig:theoretical:sequence}
    \end{figure}

    %TODO(meeting): do physical

\section{Simulation Architecture}
    \begin{landscape}
        \begin{figure}
            \centering
            \includegraphics[scale=.3]{binImages/simulator-sequence.png}
            %TODO (meeting): increase font size and increase size of figure to be as large as will fit in margin
            \caption{A sequence diagram showing the high-level interactions of
            the Spindle simulator components. A Postgres database stores the
            simulation configurations and pre-computed velocity and connectivity
            data, as well as simulation results.}
        \end{figure}
    \end{landscape}

%TODO
% DO THIS NEXT
% Ask braden what good vis tools are out there

% Want sequence diagram for a single map-reduce step
% Component diagrams showing communications
% Focus more on envisioned 
% Follow Cloud Computing papers for format (upper bound on page count is 5-10 pages)

%separate sections for envisioned architecture and for test design ("accommodations for testing")
    %TODO(meeting): describe mapping of theorized system onto simulator

\chapter{Experiments}
\section{Data Sets}
\subsection{Vehicle Traces}
   The Spindle experiments depend on a set of vehicle traces 
   generated using "the open source vehicular network simulation framework" VEINS, which simulates
   vehicle movement and radio connectivity in a "realistic" manner \cite{veins}. The VEINS traces
   were generated by Mike Wittie of the Montana State University as part of a larger overall research
   project. 
   The traces come in the form of sharded CSV files containing time-series mappings of three different types:
   speed, x-position, y-position, and connectivity to other vehicles. Each time-series mapping includes
   a timestamp, a vehicle uid, and a value (speed, position, reachable-vehicle-id). 
   These shards have been parsed into a Postgres database with a table for each mapping type.
   %TODO(MEETING): insert information about City of Cologne
   % insert information about node count, length of time here
   % Saw we pick sparse, dense region, etc... here (move from subsection below)
\subsection{Test Regions} %TODO(MEETING): make sub-sub section of Vehicle traces subsection
    \paragraph{Original VEINS Traces}
    %TODO (MEETING): insert VEINS visualization here
        The original VEINS traces span a region from $(41735, 85178.4)$ to $(63071.5, 114426)$ and includes 3340 distinct
        vehicles. This dataset includes more vehicles than the current simulator implementation can handle due to the large
        number of threads, network connections, and Kakfa topics that would be required (the thread/topic count scales with the
        number of vehicles multiplied by a constant multiple of the average number of map/reduce queries running on each node).
        A real-world deployment would distribute the threads/topics over the set of vehicles in the system such that each
        vehicle and kafka cluster would have threads and topics proportional to the number of active map/reduce queries.
        In essence, this is a temporary limitation of the simulation architecture, not the real-world architecture.

        To overcome the simulator's limitations, we defined two test regions, one dense region and one sparse region
        being transited by approximately the same number of vehicles. The sparse and dense regions were selected based
        on the number of vehicles transiting them and based on the layout of the underlying road networks.

    \begin{figure}
        \centering
        \includegraphics[scale=.5]{binImages/xiaotian-clusters.png}
        \caption{Illustration of VEINS Vehicles with MANET Clustering, Courtesy Xiaotian Duan}
        \label{fig:clusters}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics[scale=.2]{binImages/cars.png}
        \caption{A Snapshot of Active Vehicles in VEINS Traces with Selected Regions Highlighted}
        \label{fig:regions}
    \end{figure}
    \paragraph{Sparse Region}
        The sparse region is transited by 148 distinct vehicles over the course of the simulation and defines a bounding
        box from $(40000, 106800)$ to $(53000, 114000)$. The sparse region covers an area on the outskirts of the city,
        with a relatively low density of vehicles. The sparse region is illustrated by a purple box in \ref{fig:regions}.
    \paragraph{Dense Region}
        The dense region defines a bounding box from $(50000, 100000)$ to $(51000, 102000)$ and is transitied by
        131 vehicles over the course of the simulation. The dense region covers a small area near the city center
        where the density of vehicles is higher. The dense region is illustrated by an orange box in \ref{fig:regions}.

\subsection{Window Sizes}
    Kafka Streams can perform reduce operations over messages received over the course of a user-defined time-window
    and will write the results to a KTable, a logical structure whose API approximates that of a key-value store. %TODO: citations
    Spindle's Kafka Streams reducer adds a \verb|Batcher|, which transmits the final value of a time-window's KTable
    entry to some destination Kafka topic (in this case the middleware). As such, Spindle supports micro-batch operations
    on Kafka streams with user-configurable window sizes. The sizes tested were 10, 15, and 30 seconds.
\subsection{Test Clusters}
    The cluster head assignments for each node are pre-computed using either Xiaotian's %TODO: cite Xiaotian
    clustering algorithm or some base-line \verb|single_clusterhead| (all vehicles in simulation share a single clusterhead)
    or \verb|self_clusters| (all vehicles act as their own cluster heads).
\subsection{Clustering Algorithms}
    The spindle architecture takes advantage of work done by fellow RPI student Xiaotian Duan on generating
    clusters of vehicles based on vehicle connectivity and lane position. 
    %TODO: get permission from Xiaotian for using clustering images
    %TODO: include information about cluster density for each clustering (sparse/dense)
    %TODO: Fix the quotes!

\section{Test Software}
    \paragraph{SpindleSim}
        The Spindle simulator (SpindleSim) is implemented in several thousand lines of Scala %TODO: cite
        and is implemented on top of the Akka %TODO: cite
        actor model framework. The Scala/Akka portions of the simulator implement as realistically
        as is practical the software that would run on a real-world deployment of Spindle. This is
        accomplished by creating a separate Akka actor for each simulated vehicle, where each actor
        is given a cache of time-series simulation events and data and a connection to a ``World''
        actor responsible for keeping track of global simulation time; this global time-keeper 
        can be thought of as a stand-in for a GPS clock running on each vehicle. Each vehicle
        actor is then responsible for managing its publish-subscribe streams and messages, as well
        as its simulated connections to other vehicles in its cluster. Messages are exchanged between
        vehicles and send from vehicles to ``the cloud" by way of special "Stream Relay" Kakfa Streams
        programs responsible for filtering expired and "Canary" messages %TODO: explain redundant messages in architecture
        and responsible for keeping a running sum of the number of bytes sent on a per-relay basis and logging
        these sums to separate CSV files at run-time.
    \paragraph{AutoSim}
        The Scala/Akka simulator (SpindleSim) currently has a number of pre-configured map/reduce jobs written
        that can be turned on or off using the program's \verb|application.conf| file. A secondary
        program, dubbed AutoSim, runs the simulator iteratively, writing to the conf file, launching
        SpindleSim, then gathering the results and uploading them to a database and permanent storage.
        In order to iterate through the desired test configurations, AutoSim reads from a table \verb|sim_configs_vx| in a 
        Postgres 9.6.1 database hosted on an AWS EC2 \verb|m4.large| reserved instance.
        AutoSim will choose among the least-tested configurations in the configs table, write the configuration to
        the SpindleSim \verb|application.conf|, and launch an instance of SpindleSim. While SpindleSim is running, AutoSim
        greps the console logs for exception messages. If an exception is detected, the current SpindleSim instance is killed
        and a notification is sent via AWS SNS topic reporting the error message in order to facilitate debugging. If the SpindleSim
        operation completes, AutoSim uploads the CSV logs to an AWS S3 bucket and parses the final message byte sums from the CSV
        files then writes the results to a \verb|sim_results_vx| table in Postgres. AutoSim is a simple Node.JS ES6 application
        that is run from the Babel-Node %TODO: CITE
        transpiler.
    \paragraph{Environment}
        AutoSim and SpindleSim are packaged inside a docker image, \\\verb|wkronmiller/nsl-spindle-simulator| that can be run from
        a laptop, desktop, or EC2 instance. The test framework and container are designed to survive the total loss of local
        storage and/or the running simulator container by storing the results of all completed simiulation operations on
        S3 and a remote database. This design decision allows the test framework to be run on an AWS EC2 Spot Fleet %TODO: citation
        which offers discounts of roughly 70-90\% in exchange for the requirement that any software running on a Spot instance
        be designed to killed at any time with little or no warning. %TODO citation
        The architecture also enables trivial transfer of the simulator across different machines, easing debugging and mitigating
        problems related to transient EC2 network problems. 
\section{Test Configurations}
\subsection{Example Map/Reduce Programs}
    \paragraph{speedSum}
        The most simple map/reduce operation tested is the "speedSum" job, which simply maps each vehicle's available data to a
        tuple containing only the vehicle's speed. The reduce operation run at the clusterheads takes the sum of the speeds
        of each of the cluster member vehicles.
%TODO (MEETING): each paragraph should be formatted as: use case, query format
        % first sentence - query computes x
        % follow-on: uses this map function, uses reduce function
    \paragraph{geoFiltered}
        This map/reduce job extends speedSum by performing a word-count-style map operation that maps each vehicle's sensors
        to the vehicle count and the vehicle speed: \verb|(1, [speed])|. The reduce operation again simply sums the count
        and speed of each member vehicle \verb|([numVehiclesInCluster], [sumOfSpeeds])|. The geoFiltered query also is selective,
        in that for a given test region the geoFiltered query operates only on a subset of the test region containing approximately
        half of the vehicles being tested.
    \paragraph{geoMapped}
        The geoMapped query performs a similar map/reduce operation to geoFiltered, but instead of filtering out half the
        test region, the geoMapped query maps half the test region to one region ID and maps the other half of the
        test region to a second region ID, then performs a reducebykey. The map operation produces the following:
        \verb|(regionId) -> (1, [speed])| and the reduce produces \verb|(regionId) -> ([numVehiclesInCluster], [sumOfSpeeds])|.

\section{Simulator Results}
    \begin{figure}
        \centering
        \includegraphics[scale=.8]{binImages/speedSum-runplot.pdf}
        %NOTE (Meeting)
        \caption{The total number of bytes sent to the middleware,
        averaged over multiple trials for the speedSum map/reduce job. The x-axis contians different
        configurations of regions, clusterings, and reduce window sizes (10, 15, and 30 seconds). Smaller
        values in the same geographic region indicate better performance, where the best performance
        comes from using clustering with a 30 second window size.}
    \end{figure}
    %TODO (meeting): need number of trials
    %TODO (meeting): put related figures (normed not normed) on same page, try using subfig package 
    \begin{figure}
        \centering
        \includegraphics[scale=.8]{binImages/speedSum-runplot-normalized.pdf}
        \caption{shows the scaled number of bytes sent to the middleware in a given region and window size
        configuration where y=1 indicates the number of bytes sent without clustering for a given region
        and reduce window size. The figure demonstrates the data savings that occur as a result of using
        vehicle clusters. The figure also illustrates how data reduction is affected by regional vehicle
        density - areas of high vehicle density can take better advantage of clustering to get more savings.}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics[scale=.8]{binImages/geoMapped-runplot.pdf}
        \caption{shows the total number of bytes sent to the middleware,
        averaged over multiple trials for the geoMapped map/reduce job. The x-axis contians different
        configurations of regions, clusterings, and reduce window sizes (10, 15, and 30 seconds).
        Despite being a slightly different map/reduce query, the performance of the geoMapped tests
        is similar to that of the speedSum tests, where the best performing configuration is the clustered
        configuration with a 30-second reduce window size.}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics[scale=.8]{binImages/geoMapped-runplot-normalized.pdf}
        \caption{shows the scaled number of bytes sent to the middleware in a given region and window size
        configuration where y=1 indicates the number of bytes sent without clustering for a given region
        and reduce window size. The figure shows a similar reduction in data transfer by using clusters
        to that of the speedSum map/reduce job.}
    \end{figure}
    %TODO
    %GRAPHING:
        % Generating six figures
        % Message sizes:
            % Normalize with 1 being message sizes with single clusterhead
            % Plotting percentage savings with separate bars for dense/sparse wehre dense/sparse are normalized separately
        % Total bandwidth:
            % Total for dense with and without clustering
            % Total for sparse with and without clustering
        % Can include stddev bars
        % Annotate graphs with things like "this shows a reduction..."
            % try to give intuition as to why
    % maybe look at variance in data sent at clusterhead 
%TODO

\chapter{Conclusion}
%TODO: what did we do/show?
\section{Future Work}
%TODO

%\chapter{THE NEXT CHAPTER}
%And so on, for more chapters.
%Another citation for the bibliography:\cite{anotherbook}

% The following produces a numbered bibliography where the numbers
% correspond to the \cite commands in the text.
\specialhead{LITERATURE CITED}
\begin{singlespace}
\begin{thebibliography}{99}
\bibitem{thisbook} This is the first item in the Bibliography.
Let's make it very long so it takes more than one line.
Let's make it very long so it takes more than one line.
\bibitem{anotherbook} The second item in the Bibliography.
%%% TEMPLATE END
\bibitem{veins}
    http://veins.car2x.org %TODO: proper citation format (Feb 22, 17)
\bibitem{scala}
    http://www.scala-lang.org %TODO: proper citation format Feb 26, 17
\bibitem{akka}
    http://akka.io % Feb 26
\bibitem{kafka}
    https://kafka.apache.org % Feb 26
        %TODO: cite papers
\bibitem{spark}
    http://spark.apache.org/streaming/ %Feb 26
        %TODO: cite spark and spark streaming papers, not the URL
\bibitem{hitachi}
    https://www.hds.com/en-ous/pdf/white-paper/hitachi-white-paper-internet-on-wheels.pdf
\bibitem{mapreduce}
    https://research.google.com/archive/mapreduce.html
\bibitem{aws}
    http://docs.aws.amazon.com/gettingstarted/latest/awsgsg-intro/awsgsg-intro.pdf %March 1
\bibitem{spark:streaming}
    http://people.csail.mit.edu/matei/papers/2013/sosp\_spark\_streaming.pdf %March 1
\bibitem{connectivitypaper}
    @ARTICLE{6823640, 
        author={N. Lu and N. Cheng and N. Zhang and X. Shen and J. W. Mark}, 
        journal={IEEE Internet of Things Journal}, 
        title={Connected Vehicles: Solutions and Challenges}, 
        year={2014}, 
        volume={1}, 
        number={4}, 
        pages={289-299}, 
        keywords={intelligent transportation systems;next generation networks;road vehicles;vehicular ad hoc networks;Internet of Vehicles;IoV;automotive revolution;connected vehicles;next generation intelligent transportation systems;vehicle communication;vehicle-to-Internet infrastructure connectivity;vehicle-to-road infrastructure connectivity;vehicle-to-sensor infrastructure connectivity;vehicle-to-vehicle infrastructure connectivity;vehicle-to-x connectivity;wireless
        connectivities;Communication system security;Reliability;Safety;Vehicles;Wireless communication;Wireless sensor networks;Zigbee;Connected vehicles;Internet of Vehicles (IoV);intelligent transportation systems (ITSs);intra-vehicle wireless sensor networks;vehicular networks}, 
        doi={10.1109/JIOT.2014.2327587}, 
        ISSN={2327-4662}, 
        month={Aug},}

\end{thebibliography}
\end{singlespace}

%%%%%%%%%%%%%%%%%%%%%%%  For Appendices  %%%%%%%%%%%%%%%%%%%
\appendix    % This command is used only once!
\addtocontents{toc}{\parindent0pt\vskip12pt APPENDICES} %toc entry, no page #
\chapter{THIS IS AN APPENDIX}
Note the numbering of the chapter heading is changed.
This is a sentence to take up space and look like text.
\section{A Section Heading}
This is how equations are numbered in an appendix:
\begin{equation}
x^2 + y^2 = z^2
\end{equation} 

\chapter{THIS IS ANOTHER APPENDIX}
This is a sentence to take up space and look like text.

\end{document}
